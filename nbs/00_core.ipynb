{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Adapt the simpletransformer ClassificationModel to use a SmilesTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pkg_resources\n",
    "\n",
    "from rxnfp.tokenization import SmilesTokenizer\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmilesClassification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from simpletransformers.config.global_args import global_args\n",
    "from simpletransformers.classification.transformer_models.bert_model import BertForSequenceClassification\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from transformers import (\n",
    "    BertConfig\n",
    ")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    wandb_available = True\n",
    "except ImportError:\n",
    "    wandb_available = False\n",
    "\n",
    "class SmilesClassificationModel(ClassificationModel):\n",
    "    def __init__(\n",
    "        self, model_type, model_name, num_labels=None, weight=None, freeze_encoder=False, freeze_all_but_one=False, args=None, use_cuda=True, cuda_device=-1, **kwargs,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes a SmilesClassificationModel model.\n",
    "        \n",
    "        Main difference to https://github.com/ThilinaRajapakse/simpletransformers/blob/master/simpletransformers/classification/classification_model.py\n",
    "        is that it uses a SmilesTokenizer instead of the original Tokenizer\n",
    "\n",
    "        Args:\n",
    "            model_type: The type of model (bert, xlnet, xlm, roberta, distilbert)\n",
    "            model_name: The exact architecture and trained weights to use. This may be a Hugging Face Transformers compatible pre-trained model, a community model, or the path to a directory containing model files.\n",
    "            num_labels (optional): The number of labels or classes in the dataset.\n",
    "            weight (optional): A list of length num_labels containing the weights to assign to each label for loss calculation.\n",
    "            args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n",
    "            use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only.\n",
    "            cuda_device (optional): Specific GPU that should be used. Will use the first available GPU by default.\n",
    "            **kwargs (optional): For providing proxies, force_download, resume_download, cache_dir and other options specific to the 'from_pretrained' implementation where this will be supplied.\n",
    "        \"\"\"  # noqa: ignore flake8\"\n",
    "\n",
    "        MODEL_CLASSES = {\n",
    "            \"bert\": (BertConfig, BertForSequenceClassification, SmilesTokenizer),\n",
    "        }\n",
    "\n",
    "        if args and \"manual_seed\" in args:\n",
    "            random.seed(args[\"manual_seed\"])\n",
    "            np.random.seed(args[\"manual_seed\"])\n",
    "            torch.manual_seed(args[\"manual_seed\"])\n",
    "            if \"n_gpu\" in args and args[\"n_gpu\"] > 0:\n",
    "                torch.cuda.manual_seed_all(args[\"manual_seed\"])\n",
    "\n",
    "        self.args = {\n",
    "            \"sliding_window\": False,\n",
    "            \"tie_value\": 1,\n",
    "            \"stride\": 0.8,\n",
    "            \"regression\": False,\n",
    "            \"lazy_text_column\": 0,\n",
    "            \"lazy_text_a_column\": None,\n",
    "            \"lazy_text_b_column\": None,\n",
    "            \"lazy_labels_column\": 1,\n",
    "            \"lazy_header_row\": True,\n",
    "            \"lazy_delimiter\": \"\\t\",\n",
    "        }\n",
    "\n",
    "        self.args.update(global_args)\n",
    "\n",
    "        saved_model_args = self._load_model_args(model_name)\n",
    "        if saved_model_args:\n",
    "            self.args.update(saved_model_args)\n",
    "\n",
    "        if args:\n",
    "            self.args.update(args)\n",
    "\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "        if num_labels:\n",
    "            self.config = config_class.from_pretrained(model_name, num_labels=num_labels, **self.args[\"config\"])\n",
    "            self.num_labels = num_labels\n",
    "        else:\n",
    "            self.config = config_class.from_pretrained(model_name, **self.args[\"config\"])\n",
    "            self.num_labels = self.config.num_labels\n",
    "        self.weight = weight\n",
    "\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                if cuda_device == -1:\n",
    "                    self.device = torch.device(\"cuda\")\n",
    "                else:\n",
    "                    self.device = torch.device(f\"cuda:{cuda_device}\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"'use_cuda' set to True when cuda is unavailable.\"\n",
    "                    \" Make sure CUDA is available or set use_cuda=False.\"\n",
    "                )\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "\n",
    "        if self.weight:\n",
    "            self.model = model_class.from_pretrained(\n",
    "                model_name, config=self.config, weight=torch.Tensor(self.weight).to(self.device), **kwargs,\n",
    "            )\n",
    "        else:\n",
    "            self.model = model_class.from_pretrained(model_name, config=self.config, **kwargs)\n",
    "\n",
    "        self.results = {}\n",
    "\n",
    "        if not use_cuda:\n",
    "            self.args[\"fp16\"] = False\n",
    "\n",
    "        self.tokenizer = tokenizer_class(os.path.join(model_name, 'vocab.txt'))\n",
    "        \n",
    "        if freeze_encoder:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if 'classifier' in name:\n",
    "                    continue\n",
    "                param.requires_grad = False\n",
    "        elif freeze_all_but_one:\n",
    "            n_layers = self.model.config.num_hidden_layers\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if str(n_layers-1) in name:\n",
    "                    continue\n",
    "                elif 'classifier' in name:\n",
    "                    continue\n",
    "                elif 'pooler' in name:\n",
    "                    continue\n",
    "                param.requires_grad = False\n",
    "            \n",
    "\n",
    "        self.args[\"model_name\"] = model_name\n",
    "        self.args[\"model_type\"] = model_type\n",
    "\n",
    "\n",
    "        if self.args[\"wandb_project\"] and not wandb_available:\n",
    "            warnings.warn(\"wandb_project specified but wandb is not available. Wandb disabled.\")\n",
    "            self.args[\"wandb_project\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "\n",
    "Here we use the pretrained reaction BERT model from the `rxnfp` module as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    }
   ],
   "source": [
    "model_path =  pkg_resources.resource_filename(\n",
    "                \"rxnfp\",\n",
    "                f\"models/transformers/bert_pretrained\"\n",
    ")\n",
    "yield_bert = SmilesClassificationModel('bert', model_path, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert yield_bert.tokenizer.tokenize('c1ccccc1') == ['c', '1', 'c', 'c', 'c', 'c', 'c', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
